{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VpGHRyrAntQf"
   },
   "source": [
    "# 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PcDk5llfnvPo"
   },
   "source": [
    "本实验将利用Pytorch实现Word2Vec的CBOW+Negative Sampling模型，利用context word预测center word。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMTYiHKxoB5B"
   },
   "source": [
    "# 数据的载入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uQ6aFU2koD--"
   },
   "source": [
    "在本实验中将利用Penn Tree Bank语料库的文本训练数据`ptb.train.txt`进行词向量的训练。因为本实验是通过Colab进行的，所以需要首先从Colab中读取所需的数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "6szDVCQpjSQ8",
    "outputId": "e56a28da-7ee7-44fa-a05f-d65938c1b532"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "UW7fyjk5o_Kb",
    "outputId": "9d79fb8f-8f00-4c37-ed4d-b86e6047ab87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2238322.gdoc\t   'Modern Family s01e01 Episode Script | SS.gdoc'\n",
      " 2238322.pdf\t   'Modern Family s01e01 Episode Script | SS.pdf'\n",
      "'Colab Notebooks'   ptb.train.txt\n",
      " fractal.mp4\t    WechatIMG7.jpeg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"/content/drive/My Drive\"\n",
    "os.chdir(path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "oJySqloSpMse",
    "outputId": "758a2534-0fa1-4201-c201-1f0bc169aaf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of lines is 42068.\n"
     ]
    }
   ],
   "source": [
    "with open(\"ptb.train.txt\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "print(f\"The number of lines is {len(lines)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrY49hSKpZHv"
   },
   "source": [
    "我们可以看到该文本数据具有4万多行。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bn1tpCOppjNs"
   },
   "source": [
    "# 数据的读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cdfZOJqpk3I"
   },
   "source": [
    "我们需要利用空格对每行文本进行分词，并统计词频，把词频低于5的低频词从词典中删去。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BxB5FIeYqh90"
   },
   "source": [
    "首先进行粗分词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0dRD8-TxpiEV"
   },
   "outputs": [],
   "source": [
    "raw_datasets = [line.split() for line in lines]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IVJI2ZA6q6Jc"
   },
   "source": [
    "结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9R40iYH2q8QV",
    "outputId": "1c789f99-9e78-4fee-93e2-1c7373a3f309"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 6 words of the 1 line of raw datasets is \n",
      "['aer', 'banknote', 'berlitz', 'calloway', 'centrust', 'cluett'].\n",
      "\n",
      "The first 6 words of the 2 line of raw datasets is \n",
      "['pierre', '<unk>', 'N', 'years', 'old', 'will'].\n",
      "\n",
      "The first 6 words of the 3 line of raw datasets is \n",
      "['mr.', '<unk>', 'is', 'chairman', 'of', '<unk>'].\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"The first 6 words of the {i+1} line of raw datasets is \\n{raw_datasets[i][:6]}.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gaLz4MBRs3nk"
   },
   "source": [
    "由上面显示的结果，我们可以看到对于生僻词，文本中用`<unk>`表示，对于数字，文本用`N`表示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QWeYYiHktSEI"
   },
   "source": [
    "接下来我们进行词频统计与删低频词："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6paiO4O8tV8K"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counter = Counter([word for line in raw_datasets for word in line])\n",
    "counter = dict(filter(lambda x: x[1] > 5, counter.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZN6RwnGPwcVa"
   },
   "source": [
    "进行完词频统计后，我们要建议word和index之间的转换索引："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VW1Z2Nhmwkd6"
   },
   "outputs": [],
   "source": [
    "idx_to_word = [word for word, _ in counter.items()]\n",
    "word_to_idx = {word: idx for idx, word in enumerate(idx_to_word)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JjeMoaj7xJDV"
   },
   "source": [
    "结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XzmkxqNFxKis",
    "outputId": "8411af18-9b84-4e26-8175-15466f253a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The index of word 'car' is 3786.\n",
      "The word of index 3786 is car.\n"
     ]
    }
   ],
   "source": [
    "index = word_to_idx['car']\n",
    "print(f\"The index of word 'car' is {word_to_idx['car']}.\")\n",
    "print(f\"The word of index {index} is {idx_to_word[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rRdGg6ORxloh"
   },
   "source": [
    " 然后我们可以通过词典来更新我们的文本数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9y-6DGRWxsyN"
   },
   "outputs": [],
   "source": [
    "datasets = [[word_to_idx[word] for word in line if word in word_to_idx] for line in raw_datasets]\n",
    "num_words = sum([len(line) for line in datasets])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R_bBoWfMyAmn"
   },
   "source": [
    "结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "zQE6rD-NyBgC",
    "outputId": "62b656cf-bb60-4901-c4d7-2bf450fbbdd5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 1, 15, 16, 17, 1, 18, 7, 19, 20, 21]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V2C5TBvCyOrU"
   },
   "source": [
    "#二次采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMECLQiyyQ6a"
   },
   "source": [
    "我们要进行二次采样，在文本数据集中，一些高频词往往没有低频词来得重要，譬如`'the'`，我们这时可以根据词频，以一定的概率丢到部分的词，来减少高频词的词频，同时时低频词的词频变化不大，对应的丢弃概率计算公式为：\n",
    "$$\n",
    "P(w_i)=\\max\\left(1-\\sqrt{\\frac{t}{f(w_i)}},0\\right),\n",
    "$$\n",
    "其中$t=10^{-4}$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xFSvGX8Ey_ns"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def throw(idx):\n",
    "    return random.uniform(0, 1) < (1 - math.sqrt(1e-4 / counter[idx_to_word[idx]] * num_words))\n",
    "\n",
    "subsampling = [[idx for idx in line if not throw(idx)] for line in datasets]\n",
    "new_num_words = sum([len(line) for line in subsampling])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xiuy-Boy4YND",
    "outputId": "cf29c8ff-a624-4cf9-ec14-e6b43e0ae4bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before subsamping, the number of words in the dataset is 885720.\n",
      "After subsamping, the number of words in the new dataset is 374298.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before subsamping, the number of words in the dataset is {num_words}.\")\n",
    "print(f\"After subsamping, the number of words in the new dataset is {new_num_words}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cep3uWhT5pv6"
   },
   "source": [
    "这时我们要更新词频统计Counter："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zX3Jom2r53eW"
   },
   "outputs": [],
   "source": [
    "counter = Counter([idx for line in subsampling for idx in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1eTmtrR69VC"
   },
   "source": [
    "# 提取context word和center word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RY8VMwGR7a4y"
   },
   "source": [
    "每次在整数1和`max_window_size`中随机选取一个整数作为背景窗口的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XWZrAsxE8W6x"
   },
   "outputs": [],
   "source": [
    "def get_center_context(data, max_window_size=5):\n",
    "    all_centers = []\n",
    "    all_contexts = []\n",
    "    for line in data:\n",
    "        if len(line) < 2:\n",
    "            continue\n",
    "        all_centers += [[word] for word in line]\n",
    "        for index in range(len(line)):\n",
    "            window_size = random.randint(1, max_window_size)\n",
    "            indices = list(range(max(0, index-window_size), min(len(line), index+window_size+1)))\n",
    "            indices.remove(index)\n",
    "            all_contexts.append([line[idx] for idx in indices])\n",
    "    return all_centers, all_contexts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sybC2LO491WF"
   },
   "source": [
    "我们可以用一些toy data去测试一下这个函数的有效性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "slvsMRYN965P",
    "outputId": "baddf15d-aece-421f-9188-8caeb910c5f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Center: [0] -> Context: [1, 2]\n",
      "Center: [1] -> Context: [0, 2, 3]\n",
      "Center: [2] -> Context: [0, 1, 3, 4]\n",
      "Center: [3] -> Context: [1, 2, 4, 5]\n",
      "Center: [4] -> Context: [3, 5]\n",
      "Center: [5] -> Context: [3, 4, 6, 7]\n",
      "Center: [6] -> Context: [5, 7]\n",
      "Center: [7] -> Context: [5, 6]\n",
      "Center: [8] -> Context: [9]\n",
      "Center: [9] -> Context: [8, 10]\n",
      "Center: [10] -> Context: [8, 9]\n"
     ]
    }
   ],
   "source": [
    "toy_data = [list(range(8)), [8, 9, 10]]\n",
    "all_centers, all_contexts = get_center_context(toy_data, 2)\n",
    "for center, context in zip(all_centers, all_contexts):\n",
    "    print(f\"Center: {center} -> Context: {context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ydf8G5uC-jus"
   },
   "source": [
    "由上我们可以得到该函数的有效性，我们现在要用该函数去提取对应的context words和center words："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AzMyxra-rud"
   },
   "outputs": [],
   "source": [
    "all_centers, all_contexts = get_center_context(subsampling, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QNddym3P-2Or"
   },
   "source": [
    "# 负采样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcAzAptB-6tt"
   },
   "source": [
    "因为我们的模型是CBOW模型，则要求对center word进行负采样，对每个center word采样$K=4$个noise word："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_LDsGHFs_H5R"
   },
   "outputs": [],
   "source": [
    "def get_negatives(all_centers, K, sampling_weights):\n",
    "    population = list(range(len(sampling_weights)))\n",
    "    all_negatives = []\n",
    "    neg_candidate = []\n",
    "    i = 0\n",
    "    for word in all_centers:\n",
    "        negatives = []\n",
    "        while len(negatives) < K:\n",
    "            if i == len(neg_candidate):\n",
    "                neg_candidate = random.choices(population, sampling_weights, k=int(1e5))\n",
    "                i = 0\n",
    "            if neg_candidate[i] != word[0]:\n",
    "                negatives.append(neg_candidate[i])\n",
    "            i += 1\n",
    "        all_negatives.append(negatives)\n",
    "    return all_negatives\n",
    "\n",
    "sampling_weights = [counter[idx] ** 0.75 for idx in counter]\n",
    "all_negatives = get_negatives(all_centers, 4, sampling_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZHe9dj3TBO1H"
   },
   "source": [
    "#  数据读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GS_hdyaMBR1b"
   },
   "source": [
    "这时候我们需要利用Pytorch的DataLoader去读取我们的`all_centers`，`all_contexts`和，`all_negatives`："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLz3BfTdB17F"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, centers, contexts, negatives):\n",
    "        assert len(centers) == len(contexts) == len(negatives)\n",
    "        self.centers = centers\n",
    "        self.contexts = contexts\n",
    "        self.negatives = negatives\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.centers[index], self.contexts[index], self.negatives[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ayJiDnMDL-k"
   },
   "source": [
    " 在CBOW模型中，我们要把center word和negatives word链接在一起，与SkipGram不一样，每一个pair的长度都是一样的，不用补长，同时我们需要一个label向量，标记出哪个是正例，哪个是负例。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtDGifXWGGGE"
   },
   "outputs": [],
   "source": [
    "def batchify(data):\n",
    "    contexts = []\n",
    "    center_negative = []\n",
    "    labels = []\n",
    "    masks = []\n",
    "    max_len = max([len(context) for _, context, _ in data])\n",
    "    for center, context, negative in data:\n",
    "        center_negative += [center + negative]\n",
    "        labels += [[1] * len(center) + [0] * len(negative)]\n",
    "        contexts += [context + [len(idx_to_word)] * (max_len - len(context))]\n",
    "        masks += [[1] * len(context) + [0] * (max_len - len(context))]\n",
    "    return (torch.tensor(contexts), torch.tensor(center_negative),\n",
    "            torch.tensor(labels), torch.tensor(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "FdElDouVMJ27",
    "outputId": "4b5507c9-00a3-4113-f78c-222ee358d022"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contexts shape: torch.Size([512, 10])\n",
      "center_negative shape: torch.Size([512, 5])\n",
      "labels shape: torch.Size([512, 5])\n",
      "masks shape: torch.Size([512, 10])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "data = MyDataset(all_centers, all_contexts, all_negatives)\n",
    "data_iter = torch.utils.data.DataLoader(data, batch_size=batch_size,\n",
    "                                        shuffle=True, collate_fn=batchify)\n",
    "for batch in data_iter:\n",
    "    for name, data in zip(['contexts', 'center_negative', 'labels', 'masks'], batch):\n",
    "        print(name, 'shape:', data.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idR4870GtoNi"
   },
   "source": [
    "# CBOW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i87ZYKcwQ9gz"
   },
   "outputs": [],
   "source": [
    "def CBOW(contexts, center_negative, masks, embed_v, embed_u):\n",
    "    v = embed_v(contexts).sum(dim=1) /  masks.sum(dim=-1).view(-1, 1) # [batch_size, embed_size]\n",
    "    u = embed_u(center_negative) # [batch_size, c_ne_seq, embed_size]\n",
    "    pred = torch.bmm(v[:, None, :], u.permute(0, 2, 1)) # [batch_size, c_ne_seq]\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UjESIhFuv-Id"
   },
   "source": [
    "Loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3f1L-ODtv9Rm"
   },
   "outputs": [],
   "source": [
    "class SigmoidBinaryCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SigmoidBinaryCrossEntropyLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, inputs, targets):\n",
    "        inputs = inputs.float()\n",
    "        targets = targets.float()\n",
    "        loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction=\"none\")\n",
    "        return loss.mean(dim=1)\n",
    "\n",
    "criterion = SigmoidBinaryCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "0gwzpAUczYy1",
    "outputId": "8004f8f4-58e9-46d2-fa51-b3e682e64fe8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9299)"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.tensor([[1.5, 0.3, -1, 2], [1.1, -0.6, 2.2, 0.4]]).float()\n",
    "label = torch.tensor([[1, 0, 0, 0], [1, 0, 0, 0]]).float()\n",
    "criterion(pred, label).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFPvg4aNw6BY"
   },
   "source": [
    "# 初始化模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8G5Nc3Ekw736"
   },
   "outputs": [],
   "source": [
    "embed_size = 100\n",
    "net = nn.Sequential(\n",
    "    nn.Embedding(len(idx_to_word) + 1, embed_size),\n",
    "    nn.Embedding(len(idx_to_word), embed_size)\n",
    ")\n",
    "net[0].weight.data[-1] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gsof0vqHw105"
   },
   "source": [
    "训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o8wo6vPyw3es"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, lr, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"torch on {device}\")\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    loss_list = []\n",
    "    for epoch in range(num_epochs):\n",
    "        start, loss_sum, n = time.time(), 0., 0\n",
    "        for batch in data_iter:\n",
    "            contexts, center_negative, labels, masks = [d.to(device) for d in batch]\n",
    "            pred = CBOW(contexts, center_negative, masks, net[0], net[1])\n",
    "            loss = criterion(pred.view(labels.shape), labels).mean()\n",
    "            loss_sum += loss.item()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            net[0].weight.data[-1] = 0\n",
    "            n += 1\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"Epoch: {epoch+1}/{num_epochs}, Loss: {loss_sum/n:.3f}, Time: {time.time()-start:.2f}s\")\n",
    "        loss_list.append(loss_sum/n)\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "oNmBX_ck0PPD",
    "outputId": "b42b2cd5-614c-447f-ee11-ecb7a2f086ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch on cuda\n",
      "Epoch: 5/30, Loss: 0.165, Time: 3.73s\n",
      "Epoch: 10/30, Loss: 0.042, Time: 3.43s\n",
      "Epoch: 15/30, Loss: 0.012, Time: 3.82s\n",
      "Epoch: 20/30, Loss: 0.008, Time: 3.97s\n",
      "Epoch: 25/30, Loss: 0.004, Time: 3.59s\n",
      "Epoch: 30/30, Loss: 0.006, Time: 3.65s\n"
     ]
    }
   ],
   "source": [
    "loss_list = train(net, 0.01, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "id": "0VzmmoAQ43gA",
    "outputId": "a92fe2db-19c8-4184-b46a-8ee6a0d72cce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAFNCAYAAABIc7ibAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXhkZZn///edpDuh6U4a6CZh6QaU\nRVFRsEVRVMaNZVR03MBxHWcY/anj9+vyFR0X3EYdnVFHccHRQVzABRdGUUBUEGRrlB3ZtwZ6A3qj\n6SXJ/fvjnHRXh6RSSapSSfr9uq6+UvXUyam7Tk6nPnmep54TmYkkSZImVkuzC5AkSdoeGcIkSZKa\nwBAmSZLUBIYwSZKkJjCESZIkNYEhTJIkqQkMYVITRMRJEfG9Zteh8YuIr0fEh5tdR6NUnqsRsTAi\n1kVEa7PrqlVE3BkRL6hhu70jIiOibSLqksAQJhERH4iIXw9qu2WYtuMa8Pz7R8QvImJFRDwYEedE\nxAHlY8eVbyIx6HvaImJ5RLy4AbX8OCJWRsTqiLgmIt4dEa0Vb1Lryn/LIuKrETFj0D7eFBHXRsT6\niFgaEV+LiLnlY7uV++iu2P5fh2n7zTA1/iEiNkTEgoq2F0TEnfU8FsM895si4qLKtsx8a2Z+ogHP\ndXhE/Kn8OTwYERdHxNPq/TyjkZl3Z+bszOyr974j4tTyPDh2UPsXyvY31fs5pWYzhElwIfDMgb/u\nI2I3YAZw8KC2fcttaxaFkf6fzQXOAg4AuoHLgV+Uj/28fPy5g77nKCCBIYPKWETEY4HLgHuAJ2Vm\nF/AqYBEwp7LezJwNPAk4DHh7xT7eA3wWeB/QBTwD2As4LyJmZub9wK3Acyr29xzgr0O0VTvWDwPT\nufepE/gl8GVgZ2AP4GPAxmbWNQFuBt4wcKfslXo1cFvTKpIayBAmwRUUoesp5f1nA78HbhrUdltm\n3gcQEc+MiCvKXoorIuKZAzsre2o+FREXA+uBx0TEPhFxQUSsjYjzgHkD22fm5Zn5rcx8MDM3A18A\nDoiIXTJzA/AjKt6YSm8AfpCZveVzvjgiroqIVWXvyUEV9SyIiJ+WPW0PRMRXhjkOHwP+lJnvLsMS\nmXlTZr42M1cN3jgzlwPnAQeWz9NZ7uOdmfmbzNycmXdSvInuDbyu/NYLKQNXGXIPAb40qO0wqoew\n/wKOL4Pjo0TE7hFxZvma74iIf6l4bIeI+E5EPBQRN0bE/4uIJRWPnxgRt5U/qxsi4uVl++OBrwOH\nlT2Bq8r2UyPik+XtGyt7J8seyxURcUh5/xnlz2dVRFwdEUcM8/r2L4/x6ZnZl5mPZOa5mXlNuZ/H\nRsTvyp/nyoj4/kBvY/n4nRHxvrIn8+GI+FZEdEfEr8vX9duI2KncdqCH84SIuC8i7o+I9w5zXLcZ\nsivP9U+UvXRrI+LciJhXsf0bIuKuss4Px8hDg/8LHD5QG8UfG9cASyv22RIRHyr3uzwiTouIrorH\nX1/xnP86qP6Wip/vAxHxo4jYuUo9UkMZwrTdy8xNFD1AAz0xzwH+CFw0qO1CgPKX9q8ogsAuwH8C\nv4qIXSp2+3rgBIoepLuAHwBXUoSvTwBvrFLSc4ClmflAef87wCsjYofy+buAl5TtRMTBwLeBfy7r\n+QZwVkS0l4Hml2UNe1P0qJwxzPO+APhJlbq2ERG7A0cCl5ZNzwQ6gJ9WbpeZ64CzgReWTVtCGHAw\ncCNw/qC2GRQ9gsO5F/gmRegbXFcLxZv51RSv9/nA/4mII8tNPkpxLB5T1vS6Qbu4jSJ0d5X7/15E\n7JaZNwJvBS4ph+Tm8minA8dX3D8SWJmZf46IPSjOm09S9G69FzgzIuYPsZ+bgb4yLB5dEUq2vEzg\n08DuwOOBBcBJg7Z5Rfn69qc4X34NfBCYT/G7/18Gbf83wH7Ai4D3jxCWKr0WeDOwKzCzfF1ExIHA\nV4G/B3ajOJ57jLCvDRS9wAPD/m8AThu0zZvKf39D8TOcDXyl4jm/RvH/b3eK/w97VnzvO4GXUfQs\n7w48BJxc4+uU6s4QJhUuYGsIeDZFCPvjoLYLytt/C9ySmd/NzN7MPJ1iOO0lFfs7NTOvL3uqdgOe\nBnw4Mzdm5oUUIeFRImJPijeFdw+0ZebFwDLg5WXTq4GbM/Oq8v4JwDcy87Ky1+Q7FMNWzwAOpXiz\neV9mPpyZGzJzmzlNFXYB7q9yjAasLHuB7qUYFhwIbvMoAkfvEN9zP1t7/y4Anlj23Dwb+GNm3gLM\nr2i7tAzH1XwaeElEPGFQ+9OA+Zn58czclJm3UwS2gTf2VwP/lpkPZeYSijC9RWb+ODPvy8z+zPwh\ncAvFcazFD4CXRsSs8v5rKYIZFGHv7Mw8u9z3ecBi4JjBO8nMNcDhFEPO3wRWRMRZUc6by8xbM/O8\n8nxaQfGHwOAh6y9n5rLMvJfiXL4sM/9S9q7+jCLsVvpYeY5cC/wP24bJav4nM2/OzEcoem0Heo9f\nCfxvZl5U/iw/Ur6ekZwGvKE8F55LMSRf6e+B/8zM28uA/wHguLJ37pXALzPzwszcSDFk3V/xvW8F\n/jUzl5SPn0TxB46T8dUUhjCpcCHFMMjOFG/gtwB/opgrtjPwRLYOj+1O0bNU6S62/Sv/norbuwMP\nZebDg7bfRtkjci7w1TLYVTqNrUOSr2fb3oG9gPeUQ1yryoC0oHzeBcBdwwSjwR6gCIwjmVf2As0C\nLgbOKdtXAvOGeUPbrXyccojyXoqwNdDrCMXxHmgbce5dGT6+Anx80EN7AbsPOh4fpJhvB8Vxqfz5\nVN4eGEK7quJ7n0jF8PEINd1K0bP3kjKIvZQimA3U9apBdR3OMMc8M2/MzDdl5p5lDbsDXyxr7I6I\nMyLi3ohYA3xviBqXVdx+ZIj7swdtX3kc7iqfrxZLK26vr9jvNsc5M9dTnGNVlX8kzAf+lSJQPTJo\nk8H//+4C2ih+voOf8+FBz7kX8LOK438j0MfWc0OaUIYwqXAJxXDJP1EEi4HeiPvKtvsy845y2/so\nfplXWkgRLAZU/sV/P7BTROw4aPstyuGmc4GzMvNTQ9T3XeD5EXEYRQ/X9yseuwf4VGbOrfg3qwxy\n9wALa/xL/7cUQ1g1Kd8cTwWeUc4DuoSiB+7vBr222cDRFEOOAwaGJA+jCF+wtefxcGr/AMTnKIal\nnlrRdg9wx6DjMSczB3qc7mfbIarKT1nuRdHz9A5glzJsXkcx/Ae19eQMDEkeC9xQBrOBur47qK4d\nM/MzI+0wM/9KcayfWDb9W1nLkzKzk6KXLYb+7potqLi9kOI8H49tjnM5nL7L8Jtv43vAe3j0UCQ8\n+v/fQqCXImTez7Y/z1mDnvMe4OhBP4OOsrdQmnCGMIktgWIxxTDgHyseuqhsqwwFZwP7R8Rro5h4\n/RqKyem/HGbfd5X7/lhEzIyIw6kYuoxiQvs5wMWZeeIw+7izrOV04LzMrOx9+Cbw1oh4ehR2jIi/\njYg5FPOq7gc+U7Z3RMSzhjkMH6Xo+ftcRPSUte0bEd+LiknfFXW3U/TKLQUeyMzVFHOovhwRR0XE\njIjYm2KIaglFkBxwIUXP3n1l2KV8fW+gCMOXDFPj4OOyCvgP4P9VNF8OrI2I90cxCb81Ip4YW5d3\n+BHwgYjYqZyn9Y6K792RItysKF/jm9kafKB4o98zImZWKesMinlVb2NrLxgUweIlEXFkWVNHRBxR\nDkFvIyIeFxHvGXgsiuU4jmfr/Ls5wDpgdfka3lelnlp9OCJmlcO7bwZ+OM79/YTi9T6zPF4nUXtQ\n/C+K+WxDhfHTgf8bxYddZlME0h+Wvb0/AV4cxfIeMyl6SSvf574OfKoM20TE/Bi0JIY0kQxh0lYX\nUEwurpwz9ceybcubQTlh/sUUf6k/QBEAXpyZK6vs+7XA04EHKcJO5V/4L6eYx/Tm2LoG17qIWDho\nH9+h6AHYpncgMxdT9NZ9hWKi8a0UE5fJYj2nl1Asr3E3RRh6zVAFZuZtFD1TewPXR8Rq4EyKALm2\nYtNVEbGOIpAcBrw0M7Pcx79TDP19HljD1iUvnl/OwRkw1LG+CtgBuLIcuqrVlyiGlAZeRx/Fz+cp\nwB0Uw6D/TRHuoHhjXlI+9luKN+6N5ffeQBHqLilf35Moe0ZLvwOuB5ZGxJA/7yw+WXoJxQcVfljR\nfg9F79gHKULePRThaajfw2spzpfLIuJhivB1HcU5B0XYPQRYTTHZ/6dD7GO0LqA4d84HPp+Z545n\nZ5l5PcVE+DMo/hBYByynhmU2svik8PkD59Ug36YI9BdS/Aw3lM8z8Jxvpwi/91P8f1hS8b1folgO\n5tyIWEtxXJ8+ltcn1UMMfY5L0vYhIt4GHJeZgye2bxfK3so7gBk1zh0c6/PMBlYB+1UM7UvbNXvC\nJG1Xoli1/1lRrBl1AEXv0s+aXdd0FBEvKYc4d6ToHb0WuLO5VUmThyFM0vZmJsVaamsphhd/QbGe\nlervWIqJ9PdRrEF23DBDjNJ2yeFISZKkJrAnTJIkqQkMYZIkSU0w5S7VMG/evNx7772bXYYkSdKI\nrrzyypWZOdQ1YqdeCNt7771ZvHhxs8uQJEkaUUQ86jJ1AxyOlCRJagJDmCRJUhMYwiRJkprAECZJ\nktQEhjBJkqQmMIRJkiQ1gSFMkiSpCabcOmGNtOiT57Fy3aZHtc+bPZPFH3phEyqSJEnTlT1hFYYK\nYNXaJUmSxsoQJkmS1ASGMEmSpCYwhEmSJDWBIUySJKkJDGEV5s2eOap2SZKksXKJigoDy1C86ut/\nIiL40T8f1uSKJEnSdGVP2BC6OztYvmZDs8uQJEnTmCFsCD2dHSxds4HMbHYpkiRpmjKEDaGnq4MN\nm/tZ80hvs0uRJEnTlCFsCN2dHQAsdUhSkiQ1iCFsCD1dhjBJktRYhrAh9JQ9YctWG8IkSVJjGMKG\nsGtnO2BPmCRJahxD2BDa21rZadYMQ5gkSWoYQ9gwXCtMkiQ1UsNCWER8OyKWR8R1I2z3tIjojYhX\nNqqWsejp6rAnTJIkNUwje8JOBY6qtkFEtAKfBc5tYB1j0tPZwdLVG5tdhiRJmqYaFsIy80LgwRE2\neydwJrC8UXWMVXdnBw88vJHNff3NLkWSJE1DTZsTFhF7AC8HvtasGqrp6eogE5avtTdMkiTVXzMn\n5n8ReH9mjtjVFBEnRMTiiFi8YsWKCSht61phS10rTJIkNUBbE597EXBGRADMA46JiN7M/PngDTPz\nFOAUgEWLFk3IVbUHLl20zMn5kiSpAZoWwjJzn4HbEXEq8MuhAlizbLl0kT1hkiSpARoWwiLidOAI\nYF5ELAE+CswAyMyvN+p562WnWTOY2dpiT5gkSWqIhoWwzDx+FNu+qVF1jFVEsGtnuyFMkiQ1hCvm\nV9HT6YKtkiSpMQxhVXR3dbBsjUtUSJKk+jOEVVGsmr+BzAn5QKYkSdqOGMKq6Ons4JHNfazZ0Nvs\nUiRJ0jRjCKuiu8u1wiRJUmMYwqpw1XxJktQohrAqujvbAfyEpCRJqjtDWBUDly5abgiTJEl1Zgir\nomNGK3NnzbAnTJIk1Z0hbATFMhWuFSZJkurLEDaC7s4OPx0pSZLqzhA2Ai9dJEmSGsEQNoLurg5W\nrtvI5r7+ZpciSZKmEUPYCHo6O8iEFWudFyZJkurHEDaCni7XCpMkSfVnCBvBrnPKSxe5ar4kSaoj\nQ9gIerx+pCRJagBD2Ah2njWTGa3B0jXOCZMkSfVjCBtBS0uw6xzXCpMkSfVlCKtBT1cHS50TJkmS\n6sgQVoMeV82XJEl1ZgirQXe5an5mNrsUSZI0TRjCatDT1c76TX2s3djb7FIkSdI0YQirQXena4VJ\nkqT6algIi4hvR8TyiLhumMf/PiKuiYhrI+JPEfHkRtUyXltCmMtUSJKkOmlkT9ipwFFVHr8DeG5m\nPgn4BHBKA2sZl54yhHnpIkmSVC9tjdpxZl4YEXtXefxPFXcvBfZsVC3j5ar5kiSp3ibLnLC3AL9u\ndhHD6ZjRStcOM1wrTJIk1U3DesJqFRF/QxHCDq+yzQnACQALFy6coMq21VMuUyFJklQPTe0Ji4iD\ngP8Gjs3MB4bbLjNPycxFmblo/vz5E1dghe4uF2yVJEn107QQFhELgZ8Cr8/Mm5tVR616OtsdjpQk\nSXXTsOHIiDgdOAKYFxFLgI8CMwAy8+vAR4BdgK9GBEBvZi5qVD3j1dPZwcp1G+nt66etdbJMpZMk\nSVNVIz8defwIj/8j8I+Nev5627Wzg/6EFes2slvXDs0uR5IkTXF26dSoxwVbJUlSHRnCajSwVpjz\nwiRJUj0Ywmq09dJFhjBJkjR+hrAa7bLjTGa0hmuFSZKkujCE1ailJdh1TgfLHI6UJEl1YAgbhe7O\ndnvCJElSXRjCRqGny0sXSZKk+jCEjUJ3p8ORkiSpPgxho9Dd2cHDm/pYt7G32aVIkqQpzhA2CgML\ntrpWmCRJGi9D2Ci4VpgkSaoXQ9gouGq+JEmqF0PYKGwZjrQnTJIkjZMhbBR2mNlKZ0ebw5GSJGnc\nDGGj1NPV4XCkJEkaN0PYKHV3dtgTJkmSxs0QNkrdna6aL0mSxs8QNko9nR2sWLuRvv5sdimSJGkK\nM4SNUndXB/0JK9dtbHYpkiRpCjOEjZKr5kuSpHowhI2Sa4VJkqR6MISNUndXO+CliyRJ0vgYwkZp\n3o7ttLWEw5GSJGlcDGGj1NIS7Dqn3eFISZI0Lg0LYRHx7YhYHhHXDfN4RMR/RcStEXFNRBzSqFrq\nrbvLBVslSdL4NLIn7FTgqCqPHw3sV/47AfhaA2upq+45HSxb4xIVkiRp7BoWwjLzQuDBKpscC5yW\nhUuBuRGxW6Pqqaeerg6WOSdMkiSNQzPnhO0B3FNxf0nZNul1d3awdmMvD2/sbXYpkiRpipoSE/Mj\n4oSIWBwRi1esWNHscugpl6lwcr4kSRqrZoawe4EFFff3LNseJTNPycxFmblo/vz5E1JcNd3lgq0O\nSUqSpLFqZgg7C3hD+SnJZwCrM/P+JtZTM1fNlyRJ49XWqB1HxOnAEcC8iFgCfBSYAZCZXwfOBo4B\nbgXWA29uVC311tNlCJMkSePTsBCWmceP8HgCb2/U8zfSrJltzOloczhSkiSN2ZSYmD8ZdXd22BMm\nSZLGzBA2Rj2dLtgqSZLGzhA2Rt2dXrpIkiSNnSFsjHq62lm+diN9/dnsUiRJ0hRkCBujns4O+vqT\nB9Y5JClJkkbPEDZG3a4VJkmSxsEQNkZb1gpzmQpJkjQGhrAxGlg138n5kiRpLAxhY7TL7HZaW8Lh\nSEmSNCaGsDFqbQnmz253rTBJkjQmhrBx6O5yrTBJkjQ2hrBx6Olsd2K+JEkaE0PYOPR4/UhJkjRG\nhrBx6O7qYO2GXtZv6m12KZIkaYoxhI3DwDIVDklKkqTRMoSNQ4+r5kuSpDEyhI1Dd5cLtkqSpLEx\nhI3DlutHrnatMEmSNDqGsHGY3d7G7PY2e8IkSdKoGcLGqbuz3RAmSZJGzRA2Tj1drhUmSZJGzxA2\nTt2dHSxziQpJkjRKhrBx6unsYPnajfT3Z7NLkSRJU4ghbJx6ujro7U9WPuwnJCVJUu0aGsIi4qiI\nuCkibo2IE4d4fGFE/D4i/hIR10TEMY2spxEGlqlY5jIVkiRpFBoWwiKiFTgZOBo4EDg+Ig4ctNmH\ngB9l5sHAccBXG1VPo7hqviRJGotG9oQdCtyambdn5ibgDODYQdsk0Fne7gLua2A9DbGlJ8wQJkmS\nRqGtgfveA7in4v4S4OmDtjkJODci3gnsCLyggfU0xLzZM2kJQ5gkSRqdmnrCIuJdEdEZhW9FxJ8j\n4kV1eP7jgVMzc0/gGOC7EfGomiLihIhYHBGLV6xYUYenrZ+21hbmz2lnqctUSJKkUah1OPIfMnMN\n8CJgJ+D1wGdG+J57gQUV9/cs2yq9BfgRQGZeAnQA8wbvKDNPycxFmblo/vz5NZY8cXo6XbBVkiSN\nTq0hLMqvxwDfzczrK9qGcwWwX0TsExEzKSbenzVom7uB5wNExOMpQtjk6uqqQXdnh8ORkiRpVGoN\nYVdGxLkUIeyciJgD9Ff7hszsBd4BnAPcSPEpyOsj4uMR8dJys/cA/xQRVwOnA2/KzCm36mlPV4fD\nkZIkaVRqnZj/FuApwO2ZuT4idgbePNI3ZebZwNmD2j5ScfsG4Fm1lzs5dXd2sGZDL49s6mOHma3N\nLkeSJE0BtfaEHQbclJmrIuJ1FOt7rW5cWVOLa4VJkqTRqjWEfQ1YHxFPphhCvA04rWFVTTEDa4U5\nJClJkmpVawjrLedqHQt8JTNPBuY0rqyppaerHYDlaw1hkiSpNrXOCVsbER+gWJri2eVaXjMaV9bU\nYk+YJEkarVp7wl4DbKRYL2wpxZpfn2tYVVPMnI4Z7Diz1TlhkiSpZjWFsDJ4fR/oiogXAxsy0zlh\nFbq7XCtMkiTVrtbLFr0auBx4FfBq4LKIeGUjC5tqejpdK0ySJNWu1jlh/wo8LTOXA0TEfOC3wE8a\nVdhU09PZwWV3PNjsMiRJ0hRR65ywloEAVnpgFN+7XRgYjuzvn3IL/kuSpCaotSfsNxFxDsWlhaCY\nqH92le23Oz2dHfT2Jw88vIn5c9qbXY4kSZrkagphmfm+iHgFWy8xdEpm/qxxZU093Z1F8Fq2ZoMh\nTJIkjajWnjAy80zgzAbWMqUNrBW2bM0GnrhHV5OrkSRJk13VEBYRa4GhJjkFkJnZ2ZCqpqCeLq8f\nKUmSalc1hGWmlyaq0fzZ7bQELHOZCkmSVAM/4Vgnba0tzJvdbk+YJEmqiSGsjnq6Oli6ZmOzy5Ak\nSVOAIayOujs7HI6UJEk1MYTVUU9nh8ORkiSpJoawOurubGf1I5vZsLmv2aVIkqRJzhBWR5VrhUmS\nJFVjCKujLWuFOS9MkiSNwBBWRz2dLtgqSZJqYwiro+4uhyMlSVJtDGF1NKe9jVkzW1m62rXCJElS\ndQ0NYRFxVETcFBG3RsSJw2zz6oi4ISKuj4gfNLKeRosIejo77AmTJEkjqnrtyPGIiFbgZOCFwBLg\niog4KzNvqNhmP+ADwLMy86GI2LVR9UyUbtcKkyRJNWhkT9ihwK2ZeXtmbgLOAI4dtM0/ASdn5kMA\nmbm8gfVMiJ6uDj8dKUmSRtTIELYHcE/F/SVlW6X9gf0j4uKIuDQijmpgPRNi1852lq/dQGY2uxRJ\nkjSJNXtifhuwH3AEcDzwzYiYO3ijiDghIhZHxOIVK1ZMcImj09PZwea+5MGHNzW7FEmSNIk1MoTd\nCyyouL9n2VZpCXBWZm7OzDuAmylC2TYy85TMXJSZi+bPn9+wguvBtcIkSVItGhnCrgD2i4h9ImIm\ncBxw1qBtfk7RC0ZEzKMYnry9gTU1nGuFSZKkWjQshGVmL/AO4BzgRuBHmXl9RHw8Il5abnYO8EBE\n3AD8HnhfZj7QqJomwpaeMNcKkyRJVTRsiQqAzDwbOHtQ20cqbifw7vLftDB/TjsRDkdKkqTqmj0x\nf9qZ0drCvNntLHOZCkmSVIUhrAF6XLBVkiSNwBDWAN2d7U7MlyRJVRnCGqDb60dKkqQRGMIaoKez\ng4fWb2bD5r5mlyJJkiYpQ1gDDKwVtnyNy1RIkqShGcIawFXzJUnSSAxhDdDTZQiTJEnVGcIaoLvs\nCXOtMEmSNJwoFq2fOhYtWpSLFy9udhnDWvTJ81i5btOj2ufNnsniD72wCRVJkqRmiYgrM3PRUI/Z\nE1ZnQwWwau2SJGn7ZAiTJElqAkOYJElSExjCJEmSmsAQJkmS1ASGsDqbN3vmqNolSdL2qa3ZBUw3\ng5eh+MNNy3nT/1zB/3fEvk2qSJIkTUb2hDXYc/efz+H7zuO/fncLqx/Z3OxyJEnSJGEIa7CI4APH\nPI7Vj2zmq3+4tdnlSJKkScIQNgGesHsXf3fwnvzPxXey5KH1zS5HkiRNAoawCfLeI/cngM+fc1Oz\nS5EkSZOAIWyC7Na1A285fB9+ftV9XLtkdbPLkSRJTWYIm0BvO+Kx7LLjTD519g1MtQunS5Kk+jKE\nTaA5HTN41wv249LbH+R3f13e7HIkSVITNTSERcRREXFTRNwaESdW2e4VEZERsaiR9UwGxx+6kMfM\n25FP//qv9Pb1N7scSZLUJA0LYRHRCpwMHA0cCBwfEQcOsd0c4F3AZY2qZTKZ0drC+49+HLcuX8cP\nF9/T7HIkSVKTNLIn7FDg1sy8PTM3AWcAxw6x3SeAzwIbGljLpPKiA7t52t478YXzbmHdxt5mlyNJ\nkpqgkSFsD6Cyq2dJ2bZFRBwCLMjMX1XbUUScEBGLI2LxihUr6l/pBIsIPnjM41m5biOnXHh7s8uR\nJElN0LSJ+RHRAvwn8J6Rts3MUzJzUWYumj9/fuOLmwAHL9yJvz1oN7554e0sW7PddAJKkqRSI0PY\nvcCCivt7lm0D5gBPBP4QEXcCzwDO2h4m5w94/5GPo7e/n/889+ZmlyJJkiZYI0PYFcB+EbFPRMwE\njgPOGngwM1dn5rzM3Dsz9wYuBV6amYsbWNOksnCXWbzhsL358ZX38Nela5pdjiRJmkANC2GZ2Qu8\nAzgHuBH4UWZeHxEfj4iXNup5p5p3Pm9fZre38emz/9rsUiRJ0gRqa+TOM/Ns4OxBbR8ZZtsjGlnL\nZDV31kze+bz9+NTZN3LRLSs5fL95zS5JkiRNAFfMnwTe8My92HOnHfjU2TfS1+/ljCRJ2h4YwiaB\n9rZW3nfkAdx4/xp+9pd7R/4GSZI05RnCJomXHLQ7T96zi/849yY2bO5rdjmSJKnBDGGTREtLsYDr\n/as38K2L7mh2OZIkqcEMYZPI0x+zCy94fDdf+8NtrFy3sdnlSJKkBjKETTInHv04Htncx3+df0uz\nS5EkSQ1kCJtk9t11NscfuoAfXHY3t61Y1+xyJElSgxjCJqF3PX9/2tta+OyvXcBVkqTpqqGLtWps\n5s9pJ4Fzb1jG3if+apvH5s2eyeIPvbA5hUmSpLqxJ2ySWr9p6GUqVq7bNMGVSJKkRjCESZIkNYEh\nTJIkqQkMYZIkSU1gCJuCTrvkTjK90LckSVOZIWySmjd75pDtM1uDj/ziet7742u8xqQkSVOYS1RM\nUsMtQ9Hfn3zp/Fv40vm3cMVbkjYAABMPSURBVNOyNXz9dU9lz51mTXB1kiRpvOwJm2JaWoL/+8L9\n+dYbF3HXyvW85MsXcfGtK5tdliRJGiVD2BT1/Md3c9Y7D2fe7HZe/63L+MYFtzlPTJKkKcQQNoXt\nM29Hfv72Z3HUE3v49K//yjtO/wsPb+xtdlmSJKkGhrApbsf2Nk5+7SGcePTj+PW19/Pyr17MHSsf\nbnZZkiRpBIawaSAieOtzH8tp//B0VqzdyEu/chHn37is2WVJkqQqYqrNI1q0aFEuXry42WVMWvc8\nuJ63fu9Krr9vDbNmtg55DUovAi5J0sSIiCszc9FQj9kTNs0s2HkWZ77tmfzdIXt4EXBJkiaxhoaw\niDgqIm6KiFsj4sQhHn93RNwQEddExPkRsVcj69ledMxo5T9e9eRmlyFJkqpoWAiLiFbgZOBo4EDg\n+Ig4cNBmfwEWZeZBwE+Af29UPdubiGh2CZIkqYpG9oQdCtyambdn5ibgDODYyg0y8/eZub68eymw\nZwPrUYXr7l3d7BIkSdquNTKE7QHcU3F/Sdk2nLcAv25gParw4i9fxFtOvYKr7lnV7FIkSdouTYqJ\n+RHxOmAR8LlhHj8hIhZHxOIVK1ZMbHFT2HAXAd9lx5m854X7c+XdD/Gyky/m9d+6jCvufHCCq5Mk\nafvWsCUqIuIw4KTMPLK8/wGAzPz0oO1eAHwZeG5mLh9pvy5RUT/rNvbyvUvv4psX3s4DD2/iGY/Z\nmX953n4c9thdnFMmSVIdVFuiopEhrA24GXg+cC9wBfDazLy+YpuDKSbkH5WZt9SyX0NY/T2yqY8f\nXH4337jgNpav3chT99qJdzxvX47Yf75hTJKkcWhKCCuf+Bjgi0Ar8O3M/FREfBxYnJlnRcRvgScB\n95ffcndmvrTaPg1hjbNhcx8/XnwPX/vDbdy3egMH7dnFO/5mXz74s2uHXFvMRV8lSaquaSGsEQxh\njbept5+f/nkJX/3Dbdz94Pqq2975mb+doKokSZp6XDFfozKzrYXjDl3I797zXBd9lSSpQQxhGlZb\nawuveGr1pdvWbtg8QdVIkjS9GMI0Los++Vve8YM/89sblrGpt7/Z5UiSNGW0NbsATW2vedoC/vfq\n+/jlNfez06wZvPig3XnZwbtzyMKd/GSlJElVGMI0onmzZw776ciPH/tEPvziA7nw5hX8/Kr7+PGV\n9/DdS+9i4c6zOPYpu3PsU/Zg311ns+iT5/kJS0mSKvjpSNXVuo29nHPdUn5+1b1cfOtK+hOetEcX\n11a5VqWfsJQkTVfVPh1pT5jqanZ7G6946p684ql7snzNBs66+j5+cdV9zS5LkqRJx4n5aphdOzv4\nx2c/hv995+FVt7vg5hVs2Nw3QVVJkjQ52BOmpnvjty+nva2FQ/fZmefuP5/n7D+f/Xad7cR+SdK0\nZghT05365qdx4c0rufCWFXzyVzfCr25kt64Onr3fPJ6z/3wO33cec2fNBHCCvyRp2jCEaUJU+4Tl\nEQfsyhEH7ArAvase4Y83r+DCW1bwm+uW8qPFS2gJOGjPuTxn//lD7gMYtl2SpMnKT0dq0urt6+fq\nJau54OYVXHjzCq5Zsor+Kqern7KUJE02XsBb08Kq9Zt4ysfPG/bxtxy+D4cs3ImDF85l97k7TGBl\nkiQNzSUqNC0MzAsbzvcuvYtvXXQHAD2dHRyy11wOXrATh+w1lyfs3kXHjFbAeWWSpMnBEKZp49qT\njuTG+9fwl7sf4s93r+LPdz/E2dcuBWBGa3Dg7l0csnCu88okSZOCIUxTSrUJ/jPbWnjygrk8ecFc\n3vSson352g385e5V/KUMZadffnfV/W/s7aO9rbURpUuStA3nhGm7srmvn/3+9dfDPt7aEuwzb0cO\n6J7DAT1z2L/8unDnWbS2bLtumcOakqSROCdMKs1orX6RiLc997HctGwt1923mrOvu5+Bv1Ha21rY\nr3t2Ecq657B/zxyHNSVJ42IIkyq898gDttxev6mXW5at46Zla7l56VpuWraWi29dyU//fO+I+7lv\n1SP0dHbQ0lJ91X970yRp+2UI03an2ryySrNmtm2ZY1Zp1fpN3LxsHa/+xiXDPsczP/M7Zra2sMdO\nO7Bg51ksKL8u3HkWC3aaxYKdd6Brhxn2pknSdswQpu3OeHuY5s6ayaH77Fx1m0++7Inc89B6ljz4\nCHc/uJ5rlqxi1frN22wzp6P6f78Nm/u2LKtRjb1pkjQ1GcKkBnjdM/Z6VNuaDZu558H13PPgI8XX\nh9Zz2iV3DbuPx334N3R2tLFrZwe7zmmnu/w6v+J2d2dH3XrTDHOSNLEMYdIY1TqsOaCzYwZP2L2L\nJ+zetaWtWgh735EHsGzNBpav2cjytRu4/I4HWbF2I5v6+muu8RsX3MZOs2Yyd9YM5s6ayU6zZtA1\nawZzdyiW9KhUjzBnkJOk2hnCpDFqdKh4+9/s+6i2zGT1I5tZVgaz5Ws28p4fXz3sPj79678O+9iO\nM1uZWwa0nUa4GsEltz3A7PY2Zne0sWN7K7Pb29hhRisR237wYDL1ytUrEBosJTVKQ0NYRBwFfAlo\nBf47Mz8z6PF24DTgqcADwGsy885G1iRNJqPtTYuIMjjN5ICeOQBVQ9h1HzuShx7exKr1m1n1yCYe\nWr+Z1euLr6vWb2bV+k08tH4Tqx7ZPOw+AI7/5qWPamsJ2HFmGzu2bw1m1fz3H2+nfUYrHW0tW752\nzGgt/5W324rb9Qhz9QqEk6mHcLqFU2uxlqlaS700LIRFRCtwMvBCYAlwRUSclZk3VGz2FuChzNw3\nIo4DPgu8plE1SZNNo//Dz25vY3Z7Gwuqf44AgL1P/NWwj33/H5/Ouo29PFz+W7exr/xatm0q2qr5\n5K9uHG35Q3r2v/+OGa0tzGxtYWZbCzNaW5jRGsxobaF9y/3q68F94bybaW2Jrf9i6+2WlqCtoq2a\nC25eQUtAaxTf1xJBa0sRllujuN/SUj3ILXloPRFBS0BQfCWgJYKg/BrFPqvt55FN1Y9/5bbDtff2\n9W+tJaq/9ukWlK3FWprxqfRG9oQdCtyambcDRMQZwLFAZQg7FjipvP0T4CsRETnVlvGXmmi0vWlj\n8ax959W0XbUgd81JL2LD5j42bu5nw+Y+NmzuZ0Nv35bbG3vLts19fOjn1w27n0V77cymvn429/az\nua+fzX3Jpt5+1m7u5cG+rW3VfOn8W2p6PSN547cvH/c+Dv/s7+tQCTz+I78Z9z72HXQ1iRgyDBa3\nqzns0+eXgbT4F2VQLW4XQbV1hH38w6lXFCE22BKOB/YxEHZbyvBbzefPuWlLqBzYX0tZ05b7I9Ty\nwyvuJtgahlsGHYeBYzPSfn5z3dKKe8U5WvluV8sb31lX31d+36O3HmjKGvZ02iV30tef9PUn/Zn0\n9UN/Jv39SV/F12re++Or6etPevuTvv7+LfvrLb9W3q7m+f/xh6LiLI5BZvEK+jPJ3PYYDeeoL17I\njNYW2lqDGS0ttLZEcbu1hbaW4utA22TSyBC2B3BPxf0lwNOH2yYzeyNiNbALsLKBdUnTSr160xod\n5jo7ZtDZMaOmbauFsC+85ik17aNaILzj08cUbxK59c2ivx96+/vLN6Didn8/POdzw4ekM992GP3J\nljey/vKNbOBNbOCxt37vymH38e+vPKh400noz+INtL94JyruD3wFPvHLG4bdz4lHP66Ww8JnqswT\nfM8L99+mhq11DX5TTL75xzuG3c/h+87b9hhsuV3xZj/CO+vytRvo6y+eq29QMOjvrzjmI+znaxfc\ntqXusXr/mdeO/ZsrVDsPavUvp/+lDpXAR35x/YjbjNQTfMltDxTBprIHeYj7M0dYaudxPZ0QEBQh\ntwj9W29T9hKf+eclw+5jwc6z6O3rp7c/6e1Levv7eWRz8bW3L9ncV4TEkf5Am2hTYmJ+RJwAnACw\ncOHCJlcjTU/1CHMT0StXDxHFX8Tj/QX41L1qGOcdwasXLah522oh7K3PfWxN+6gWwt75/P1qrqVa\nCPvcq55c0z6qBeVfvvPZNddSbT+3/dsxwLaBsj+3BsqB0HzQSecOu48/nfi8bXplKkNqf9mFM7DP\no774x2H386t/OZwyVgBFb1rlVyjCxpFfvHDYffz23c+Bch/bft/AvmLL/SM+/4dh97P4Qy/YMow+\nMCTfUvYutlb0MFY7thef+LxhHxus2n5O/vtDatpHtRD2zTcMeWnGUdcy0RoZwu4FKn+77Fm2DbXN\nkohoA7ooJuhvIzNPAU6B4gLeDalW0rhNpl65egXCqRIsVV0MDBky+uGo3efuUJcaKpenGat9d51T\nh0pg3uz2uuxH49PIEHYFsF9E7EMRto4DXjtom7OANwKXAK8Efud8MEn1CHP1CoSTqYdwuoVTa7GW\nqVpLvUQjM09EHAN8kWKJim9n5qci4uPA4sw8KyI6gO8CBwMPAscNTOQfzqJFi3Lx4sUNq1mSJKle\nIuLKzBxyvLShc8Iy82zg7EFtH6m4vQF4VSNrkCRJmoyqL6YjSZKkhjCESZIkNYEhTJIkqQkMYZIk\nSU1gCJMkSWoCQ5gkSVITGMIkSZKaoKGLtTZCRKwA7pqAp5qHFxJvFI9t43hsG8vj2zge28by+DbO\nSMd2r8ycP9QDUy6ETZSIWDzcCrcaH49t43hsG8vj2zge28by+DbOeI6tw5GSJElNYAiTJElqAkPY\n8E5pdgHTmMe2cTy2jeXxbRyPbWN5fBtnzMfWOWGSJElNYE+YJElSExjCBomIoyLipoi4NSJObHY9\n001E3BkR10bEVRGxuNn1TGUR8e2IWB4R11W07RwR50XELeXXnZpZ41Q2zPE9KSLuLc/fqyLimGbW\nOFVFxIKI+H1E3BAR10fEu8p2z99xqnJsPXfrICI6IuLyiLi6PL4fK9v3iYjLyuzww4iYWdP+HI7c\nKiJagZuBFwJLgCuA4zPzhqYWNo1ExJ3Aosx0vZpxiojnAOuA0zLziWXbvwMPZuZnyj8idsrM9zez\nzqlqmON7ErAuMz/fzNqmuojYDdgtM/8cEXOAK4GXAW/C83dcqhzbV+O5O24REcCOmbkuImYAFwHv\nAt4N/DQzz4iIrwNXZ+bXRtqfPWHbOhS4NTNvz8xNwBnAsU2uSRpSZl4IPDio+VjgO+Xt71D88tUY\nDHN8VQeZeX9m/rm8vRa4EdgDz99xq3JsVQdZWFfenVH+S+B5wE/K9prPXUPYtvYA7qm4vwRP3npL\n4NyIuDIiTmh2MdNQd2beX95eCnQ3s5hp6h0RcU05XOlw2ThFxN7AwcBleP7W1aBjC567dRERrRFx\nFbAcOA+4DViVmb3lJjVnB0OYJtrhmXkIcDTw9nLIRw2QxVwD5xvU19eAxwJPAe4H/qO55UxtETEb\nOBP4P5m5pvIxz9/xGeLYeu7WSWb2ZeZTgD0pRtAeN9Z9GcK2dS+woOL+nmWb6iQz7y2/Lgd+RnEC\nq36WlXNCBuaGLG9yPdNKZi4rfwH3A9/E83fMyvk0ZwLfz8yfls2ev3Uw1LH13K2/zFwF/B44DJgb\nEW3lQzVnB0PYtq4A9is/5TATOA44q8k1TRsRsWM5UZSI2BF4EXBd9e/SKJ0FvLG8/UbgF02sZdoZ\nCAill+P5Oybl5OZvATdm5n9WPOT5O07DHVvP3fqIiPkRMbe8vQPFB/lupAhjryw3q/nc9dORg5Qf\n2/0i0Ap8OzM/1eSSpo2IeAxF7xdAG/ADj+/YRcTpwBHAPGAZ8FHg58CPgIXAXcCrM9PJ5WMwzPE9\ngmI4J4E7gX+umMOkGkXE4cAfgWuB/rL5gxRzlzx/x6HKsT0ez91xi4iDKCbet1J0ZP0oMz9evr+d\nAewM/AV4XWZuHHF/hjBJkqSJ53CkJElSExjCJEmSmsAQJkmS1ASGMEmSpCYwhEmSJDWBIUySahQR\nR0TEL5tdh6TpwRAmSZLUBIYwSdNORLwuIi6PiKsi4hvlBXfXRcQXIuL6iDg/IuaX2z4lIi4tL2z8\ns4ELG0fEvhHx24i4OiL+HBGPLXc/OyJ+EhF/jYjvlyuUS9KoGcIkTSsR8XjgNcCzyovs9gF/D+wI\nLM7MJwAXUKyAD3Aa8P7MPIhilfGB9u8DJ2fmk4FnUlz0GOBg4P8ABwKPAZ7V8BclaVpqG3kTSZpS\nng88Fbii7KTageJC0P3AD8ttvgf8NCK6gLmZeUHZ/h3gx+U1TvfIzJ8BZOYGgHJ/l2fmkvL+VcDe\nwEWNf1mSphtDmKTpJoDvZOYHtmmM+PCg7cZ6zbbK68H14e9RSWPkcKSk6eZ84JURsStAROwcEXtR\n/L57ZbnNa4GLMnM18FBEPLtsfz1wQWauBZZExMvKfbRHxKwJfRWSpj3/gpM0rWTmDRHxIeDciGgB\nNgNvBx4GDi0fW04xbwzgjcDXy5B1O/Dmsv31wDci4uPlPl41gS9D0nYgMsfaIy9JU0dErMvM2c2u\nQ5IGOBwpSZLUBPaESZIkNYE9YZIkSU1gCJMkSWoCQ5gkSVITGMIkSZKawBAmSZLUBIYwSZKkJvj/\nAdL5YrY/unADAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_list, marker='s')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Word2Vec CBOW Negative Sampling Model')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bZ-88cZf2MRR"
   },
   "source": [
    "#应用词嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "21tdjLeH2Lj0"
   },
   "outputs": [],
   "source": [
    "def get_similarity(word, k, embed):\n",
    "    W = (embed[0].weight.data[:-1] + embed[1].weight.data) * 0.5\n",
    "    x = W[word_to_idx[word]]\n",
    "    cos = torch.matmul(W, x) / (torch.sum(W * W, dim=-1) * torch.sum(x * x) + 1e-9).sqrt()\n",
    "    _, topk = torch.topk(cos, k+1)\n",
    "    for i in topk[1:]:\n",
    "        print(f\"cosine sim={cos[i]:.3f}: {idx_to_word[i]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "Ycx3hGnS3AoP",
    "outputId": "56f0a7a3-0974-4530-c505-869ce1a5b90f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine sim=0.426: husband.\n",
      "cosine sim=0.401: her.\n",
      "cosine sim=0.372: woman.\n",
      "cosine sim=0.349: respectable.\n"
     ]
    }
   ],
   "source": [
    "get_similarity(\"mother\", 4, (net[0], net[1]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CBOW-NS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
