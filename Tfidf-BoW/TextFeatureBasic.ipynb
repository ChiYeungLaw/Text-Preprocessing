{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "idl0uU_HlVxW"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In this note, I will introduce two basic text feature extration methods.\n",
    "- tf-idf\n",
    "- Bag of words (BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZF5NGzLltea"
   },
   "source": [
    "# Raw data\n",
    "\n",
    "First we need to get some raw text data. We use the [Review polarity v2.0](http://www.cs.cornell.edu/people/pabo/movie-review-data/) data set created by Bo Pang and Lillian Lee at Cornell University. It consists of 2000 movie reviews, 1000 of which are positive and 1000 are negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X19M0Uq4mgJm",
    "outputId": "bf12efd9-ea88-44a4-93dd-d1acf9d75c82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poldata.README.2.0  review_polarity.tar.gz  sample_data  txt_sentoken\n"
     ]
    }
   ],
   "source": [
    "data_url = \"http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz\"\n",
    "fn = data_url.split(\"/\")[-1]\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(data_url, fn)\n",
    "t!ar zxf review_polarity.tar.gz\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r0rkdVAEosP-"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dParJhTBo3wV"
   },
   "source": [
    "Read the whole datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ZyI-gIJDo6jL",
    "outputId": "097062f6-569b-4706-e648-cd1b3758236b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of files is 2000.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "filenames = list()\n",
    "for root, dirs, files in os.walk(\"./txt_sentoken\"):\n",
    "  # Python method walk() generates the files names\n",
    "  # in a directory tree by walking the tree either\n",
    "  # top-down or bottom-up\n",
    "  for names in files:\n",
    "    filenames.append(os.path.join(root, names))\n",
    "print(f\"The number of files is {len(filenames)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h4pUrHzLqhQ9"
   },
   "source": [
    "Then we need to use all the address to read the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "dsFzxuW4qk9i",
    "outputId": "03dca997-b553-4af5-f8c9-0f56eab7bc00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./txt_sentoken/pos/cv919_16380.txt positive example\n",
      "./txt_sentoken/pos/cv428_11347.txt positive example\n",
      "./txt_sentoken/pos/cv999_13106.txt positive example\n",
      "./txt_sentoken/neg/cv354_8573.txt negative example\n",
      "./txt_sentoken/pos/cv464_15650.txt positive example\n",
      "./txt_sentoken/neg/cv922_10185.txt negative example\n",
      "./txt_sentoken/pos/cv406_21020.txt positive example\n",
      "./txt_sentoken/neg/cv559_0057.txt negative example\n",
      "./txt_sentoken/neg/cv589_12853.txt negative example\n",
      "./txt_sentoken/pos/cv417_13115.txt positive example\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "X_txt = list()\n",
    "y = list()\n",
    "random.shuffle(filenames)\n",
    "for i, fn in enumerate(filenames):\n",
    "  if fn.find(\"/pos/\") > 0:\n",
    "    msg = \"positive\"\n",
    "    y.append(1)\n",
    "  else:\n",
    "    msg = \"negative\"\n",
    "    y.append(-1)\n",
    "  with open(fn, encoding=\"utf-8\") as f:\n",
    "    X_txt.append(f.read())\n",
    "  if i < 10:\n",
    "    print(fn, msg, \"example\")\n",
    "y = np.asarray(y)\n",
    "assert len(X_txt) == y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v5Qzop29reQ5"
   },
   "source": [
    "We can see what we get in the `X_txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "4A1McD-8rhxq",
    "outputId": "f2541747-7256-4a41-9c97-2cb3a1052cc9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when i first heard that kevin costner was making a movie called \" the postman , \" i thought , \" an american version of \\'il postino ? \\' \\nstarring costner ? \\ngod help us ! \" \\nwhen i found out that it was not a remake of \" postino \" but an postapocalyptic epic , i thought , \" \\'landworld ? \\' \\nplease , god , make him stop ! \" \\nas it turns out , \" the postman \" is a much better film than i had expected . \\ndespite being set in 2013 , the movie is , at heart , a western : a band of thugs terrorizes peaceful villagers ; a wandering hero opposes the bandits and inspires others to fight back . \\nthe setting , however , allows that familiar plot to take on greater significance : american society has collapsed due to plagues and wars , and survivors live behind barracades in isolated villages . \\nthe struggle of a dead society to be reborn has a grand quality and deserves the epic scale costner grants it . \\ncostner\\'s nameless character , a wandering actor , rides in from the vast wasteland and is soon shanghaied into the service of general bethlehem ( will patton ) , a former copy-machine salesman turned bandit king . \\nour hero escapes and discovers the body of a dead postman . \\ntaking the uniform and bag of mail , he passes himself off as a representative of \" the restored united states . \" \\nhe is shocked at the hope that he inspires in the people he meets . \\none young disciple , ford lincoln mercury ( larenz tate ) , organizes a full-scale postal service . \\nford spreads the postman\\'s message of hope until bethlehem finds that the once-meek villagers are beginning to resist his rule . \\nas war breaks out between bethlehem\\'s army and the postal workers , costner\\'s character steps into the legend he created and goes from self-centered loner to leader of the revolution . \\nhis lie of the restored united states becomes a self-fulfilling prophecy . \\n \" postman \" is an odd blend of a bleak setting and a message of wide-eyed optimism ( sort of \" sergio leone meets frank capra \" ) , but its treatment of hope and renewal is compelling . \\nwhat could have been another knock-off of \" the road warrior \" ( like \" waterworld \" was ) surprises the viewer with a sensitively told story of nobility emerging from rubble . \\ntate is the stand-out in the movie\\'s large cast . \\nford lincoln mercury ( self-named ) is the polar opposite of o-dog , tate\\'s character in his debut film , \" menace ii society \" ( 1993 ) , and tate makes ford\\'s innocent belief in hope as convincing as o-dog\\'s cynicism and brutality . \\nhis performance sells the movie . \\ninterestingly , as tate moves from his usual street-smart roles to youthful optimism , the soft-eyed patton , who usually plays nice guys , proves a disarming villain . \\nolivia williams makes her film debut as the postman\\'s love interest , abby . \\nwhen they first meet , abby asks him to father her child because her husband is sterile . \\npredictably , the husband is soon eliminated by the bandits , and abby is thrown back into the company of the hero . \\nhowever , their relationship develops slowly as the emotional conflicts of both characters are explored ( she , torn by grief , guilt , and anger ; he , resisting his destiny ) . \\n \" the postman \" is costner\\'s best work thus far . \\nperhaps that alone gives us hope for the future . \\n . \\n . \\n',\n",
       " \"on april 12th , 1912 , the most astonishing shipwreck in the history of the world occurred . \\non that fateful night , the titanic sunk . \\nnow , more than 50 years later , a film has been made . \\nand what a film that is . \\njames cameron's newest movie is a landmark in storytelling , emotion , and special effects . \\nit starts in the present , where bill paxton and his band of scientists explore the depths of the ship's wreckage . \\nexploring an old chest , paxton comes across a nude drawing of a young woman . \\nthe drawing is televised and the woman ( gloria stuart ) whose portrait the painting is of comes forward and slowly but surely , the ship's story is told . \\nleonardo dicaprio stars as jack dawson , a young man with a sketch book , a heart of gold , an intelligent mind , and not much else . he wins his ticket aboard titanic in a poker game , and is the perfect match for rose dewitt bukater ( kate winslett ) . \\nshe grows to love jack , but seems unable to escape the slimy clutches of her arranged fiance' , cal hockley ( billy zane ) . \\nthe film takes its time , and by doing so , makes us care about its characters , and shows us the full aspects of human emotion . \\nthe leads shine ; there is no bad performance ; in fact , these do not seems like performances at all , but genuine people , trapped on the doomed vessel , facing certain death . \\nwatching this film , i was amazed at how vivid and real these situations feel : the time rose and jack spend together at a third-class-party ; the naivety that jack feels when he skecthes rose nude ; the terror felt by all onboard , as certain doom turns people into both cowards and heroes . \\nthis , the most expensive movie ever made , $200 million , is destined to make its profit back , and then some . \\nit also has more emotion and warmth than any other film this year . . even this decade . \\nit is also yet another first : the first $200 million dollar romance , and every critic in this country will agree that it was indeed , money extremely . . very \\n . . well \\nspent . \\n\",\n",
       " 'truman ( \" true-man \" ) burbank is the perfect name for jim carrey\\'s character in this film . \\npresident truman was an unassuming man who became known worldwide , in spite of ( or was it because of ) his stature . \\n \" truman \" also recalls an era of plenty following a grim war , an era when planned communities built by government scientists promised an idyllic life for americans . \\nand burbank , california , brings to mind the tonight show and the home of nbc . \\nif hollywood is the center of the film world , burbank is , or was , the center of tv\\'s world , the world where our protagonist lives . \\ncombine all these names and concepts into \" truman burbank , \" and you get something that well describes him and his artificial world . \\ntruman leads the perfect life . \\nhis town , his car , and his wife are picture perfect . \\nhis idea of reality comes under attack one day when a studio light falls from the sky . \\nthe radio explains that an overflying airplane started coming apart . \\n . \\n . \\nbut then why would an airplane be carrying a studio light ? \\nthe next day during the drive to work , the radio jams and he starts picking up a voice that exactly describes his movements . \\nhe is so distracted that he nearly hits a pedestrian . \\nwhen the radio comes back to normal , the announcer warns listeners to drive carefully . \\nhis suspicion aroused , he wanders around the town square looking for other oddities . \\nthe world appears to be functioning properly until he enters an office building and tries to take the elevator . \\nthe elevator doors open up on a small lounge with people on coffee breaks . \\na grip sees truman him and quickly moves a paneled door , made to look like the back of an elevator , into place . \\ntwo security guards grab him and throw him out . \\ntruman is really suspicious now . \\nit gets even worse the next day when his wife , a nurse , describes an elevator accident in the building where he saw the lounge . \\n \" it\\'s best not to think about it , \" she says , trying vainly to change truman\\'s memory . \\ntruman becomes determined to see who or what is behind this apparently elaborate hoax at his expense . \\nat every turn he is stopped by an amazing coincidence that just happens to keep him in his own little town . \\nhis last hope is to quell his fear of the ocean and sail to the edge of the world . \\nyou know by now that truman\\'s life is the subject of a television program . \\nhis actions are \" real \" but everything else is carefully scripted , from the death of his father to the choice of his wife . \\ntruman is determined to find out what the big hoax is . \\nmeanwhile , christof , the all-seeing creator of truman\\'s world does his best to keep him unaware and happy . \\nit\\'s sort of like westworld told from the robots\\' point of view , or jurassic park from the dinosaurs\\' point of view . \\nwe root for the captive of the cage-world . \\nour protagonist is counting on \" chaos theory \" to help him escape his elaborate trap . \\nthe story , written by andrew niccol ( writer/director of gattaca ) , introduces some interesting questions , such as the ethics of subjecting a person to this type of life , or the psychological impact of learning that your entire life has all been fake . \\nalthough these questions came to mind , i don\\'t think the film itself asked them . \\nit certainly didn\\'t address them or try to answer them . \\ni was particularly disappointed that the film didn\\'t deal more with the trauma of learning one\\'s life is a tv show . \\ncarrey\\'s performance at the end showed a smidgen of truman\\'s pain , but i almost felt that he got over it too easily for the sake of the film\\'s pacing . \\nearlier in the movie i found myself wondering if it would be better for truman to find out the truth or whether i should root for him to be well . \\nthe two seemed exclusive of one another , but weir and niccol didn\\'t see it that way . \\nperhaps it\\'s not fair to criticize a movie for what it isn\\'t , but it seems like there were some missed opportunities here . \\nbut on its own terms , the movie is well made . \\nsight , sound and pacing are all handled competently . \\nmuch of the first part of the movie is the truman show . \\nthe scenes are all apparently shot from hidden cameras , with snoots and obstructions covering the corners of the screen . \\none hidden camera is apparently in his car radio , the green led numbers obscuring the lower part of the screen . \\nthe music is well-chosen and scored . \\nthe film opens with what sounds like family drama theme music , when truman\\'s world is still beautiful and perfect . \\nwhen the movie ends , the score sounds more like a frantic , driven , tangerine dream opus , while still keeping the same timbre . \\nphilip glass\\' epic music ( from powaqqatsi ) permeates truman\\'s scenes of suspicion and awakening . \\n ( glass has a small cameo as a keyboardist for the show . ) \\nand the pacing of the story was brisk . \\nthere was no unnecessarily long setup explaining the concept behind the truman show , just a few quick title cards , a few interviews , and then right into the show , and the movie . \\none of the first scenes is of the studio light falling ; there was no token scene of truman\\'s idyllic life before it falls apart , because it wasn\\'t necessary , we pick up the story at the first sign of trouble , and no sooner . \\nthere\\'s also no point in the movie where the plot slows down . \\nit\\'s a quick , straight shot to the movie\\'s end . \\nin terms of overall quality , i would compare the truman show to niccol\\'s gattaca . \\nboth films are well made with interesting stories set in interesting worlds . \\nbut neither film really felt like it capitalized on all the great ideas ; neither film \" clicked \" and became an instant classic . \\nnevertheless , i look forward to niccol\\'s next film , whatever it may be . \\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_txt[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iT1ghDRtsNSc"
   },
   "source": [
    "We can find a histogram over the length of the reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 334
    },
    "colab_type": "code",
    "id": "FH87vYK5sTfF",
    "outputId": "e7faa909-a493-46b7-cd81-c0df2e34510f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAU0AAAE9CAYAAACP0jAFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWQFOmmZmBfwH2DPTjP5IHWUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.hist([len(x) for x in X_txt], 55)\n",
    "plt.xlabel(\"# characters\")\n",
    "plt.ylabel(\"Number of documents\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wo2ud1iAxXuo"
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-8lBktRGxeM7"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "Here I use nltk to tokenize our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "NWn5PyIAxnVa",
    "outputId": "efe0c4fa-33f6-4aa8-fbfc-653fb2943f2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "txt_tok = []\n",
    "for sent in X_txt:\n",
    "  txt_tok.append(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DvwcWWOvyNuJ"
   },
   "source": [
    "## Remove Stopwords and Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "BlIncKbvyTBy",
    "outputId": "29e39e3a-9199-45d6-ecec-9f4dd8108a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "punct = string.punctuation\n",
    "txt_tok_re = []\n",
    "sent = []\n",
    "voc = []\n",
    "for se in txt_tok:\n",
    "  sent = []\n",
    "  for word in se:\n",
    "    if word not in stopwords and word not in punct:\n",
    "      sent.append(word.lower())\n",
    "      if word not in voc:\n",
    "        voc.append(word.lower())\n",
    "  txt_tok_re.append(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHgJGPVozxNe"
   },
   "source": [
    "Then we can get our clean text data and the vocabulary `voc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MYfhNSvz7cu"
   },
   "outputs": [],
   "source": [
    "voc.append('<unk>')\n",
    "random.shuffle(voc)\n",
    "voc = dict([(word, i) for i, word in enumerate(voc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "PYUZtmrp0fij",
    "outputId": "f508880f-e2b7-4b93-b43b-ca6026e46148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8753"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc['dolphin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1-zMv8IXs-Pl"
   },
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F3NKshHqtB_V"
   },
   "source": [
    "## ti-idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Ll6IgoTtG9-"
   },
   "source": [
    "**Tf-idf** stands for term frequency-inverse document frequency. It's a technique to measure how important a word to a document in a corpus. The importance increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lrZmNXBsu_05"
   },
   "source": [
    "### Term Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7azvaSenvEEI"
   },
   "source": [
    "Measure the number of times a word in a document.\n",
    "$$\n",
    "\\begin{equation}\n",
    "t_{ij}=\\frac{n_{ij}}{\\sum_k n_{kj}}.\n",
    "\\end{equation}\n",
    "$$\n",
    "This represents that the term frequency of word $w_i$ in document $d_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OdkKrVIzv-Hs"
   },
   "source": [
    "### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HfaQmIHwBTa"
   },
   "source": [
    "If a word appear many times in the corpus, it's less important in a document.\n",
    "$$\n",
    "\\begin{equation}\n",
    "idf_i=\\log\\left(\\frac{|D|}{|{j,t_i\\in d_j}|+1}\\right).\n",
    "\\end{equation}\n",
    "$$\n",
    "$|D|$ is the number of documents. $|j, t_i\\in d_j|$ means the number of documents that contains word $t_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U2c29PFOw22p"
   },
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "koJXGF-q8snc"
   },
   "source": [
    "First, we need to compute the idf for each word in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zeZeo1c2xAqs"
   },
   "outputs": [],
   "source": [
    "idf = dict()\n",
    "for word in voc:\n",
    "  idf[word] = 0\n",
    "  for sent in txt_tok_re:\n",
    "    if word in sent:\n",
    "      idf[word] += 1\n",
    "      break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sppuWCtA9l0_"
   },
   "outputs": [],
   "source": [
    "for word in idf:\n",
    "  idf[word] = np.log(2000 / (idf[word] + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TaKFpATG_Ta8"
   },
   "source": [
    "Then we compute the **tfidf** vector for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ONTzs0am_YIl"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "X_vector = np.zeros((2000, len(voc)))\n",
    "for i in range(2000):\n",
    "  sent = txt_tok_re[i]\n",
    "  c = Counter(sent)\n",
    "  for word in c:\n",
    "    X_vector[i, voc[word]] = c[word] / len(sent) * idf[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8tFg6IVH1Wv"
   },
   "source": [
    "Then we can use **Logistic Regression** to test our **tfidf** vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_rHEVN7RH7_-",
    "outputId": "396ecba5-dcf2-4e57-fc05-08c82d2e7a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.832"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression().fit(X_vector, y)\n",
    "LR.score(X_vector, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHDhYjsGIUlM"
   },
   "source": [
    "### Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vo-XUhsFJqx7"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stopwords)\n",
    "tfidf.fit(X_txt)\n",
    "X = tfidf.transform(X_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnwaMalIJ9xP"
   },
   "source": [
    "Then we can use **Logistic Regression** to test our **tfidf** vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ae2K4yU6J-8a",
    "outputId": "b2d45138-fa29-4572-98f1-365ac56ac7e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.977"
      ]
     },
     "execution_count": 97,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogistiRegression().fit(X, y)\n",
    "LR.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a5D2LVYfKU20"
   },
   "source": [
    "## BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cW1_l2hWKZvf"
   },
   "source": [
    "**Bag-of-word** is a really simple feature extraction method. It just transforms a text to a one-hot vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fUNBNy_MKjvi"
   },
   "source": [
    "### Python Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t_oDrh4OKmTx"
   },
   "outputs": [],
   "source": [
    "X_bow = np.zeros((len(txt_tok_re), len(voc)))\n",
    "for sent_i in range(len(txt_tok_re)):\n",
    "    for word in txt_tok_re[sent_i]:\n",
    "        X_bow[sent_i, voc[word]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gK4IilWLYzX"
   },
   "source": [
    "Then we can use **Logistic Regression** to test our **BOW** vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Oe00OLGHLhLO",
    "outputId": "4e39f0d3-a7da-4057-cb60-e9e4703c75dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression().fit(X_bow, y)\n",
    "LR.score(X_bow, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WNhZ6brFLrFI"
   },
   "source": [
    "### Sklearn Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NqKTpJWDLuzR"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow = CountVectorizer(stop_words=stopwords)\n",
    "bow.fit(X_txt)\n",
    "X = bow.transform(X_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "edxC-4OeMB6i",
    "outputId": "c01f320b-8f9e-4594-fbc7-499927da75bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR = LogisticRegression().fit(X, y)\n",
    "LR.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CZF5NGzLltea",
    "Wo2ud1iAxXuo",
    "-8lBktRGxeM7",
    "DvwcWWOvyNuJ",
    "1-zMv8IXs-Pl",
    "F3NKshHqtB_V",
    "a5D2LVYfKU20"
   ],
   "name": "TextFeatureBasic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
